---
title: "forcats: Working with Categorical Data"
output: learnr::tutorial
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(learnr)
library(forcats)
library(tibble)
library(magrittr)
library(purrr)
library(dplyr)
library(ggplot2)
library(readr)
knitr::opts_chunk$set(echo = FALSE)
ecom <- readr::read_csv('https://raw.githubusercontent.com/rsquaredacademy/datasets/master/web.csv')
traffic <- read_csv('https://raw.githubusercontent.com/rsquaredacademy/datasets/master/web_traffic.csv',
  col_types = list(col_factor(levels = c("google", "facebook", "affiliates", 
    "bing", "yahoo", "twitter", "instagram", "unknown", "direct"))))
traffics <- 
  traffic %>%
  use_series(traffics)
response <- read_csv('https://raw.githubusercontent.com/rsquaredacademy/datasets/master/response.csv',
  col_types = list(col_factor(levels = c("like", "like somewhat", "neutral", 
    "dislike somewhat", "dislike"), ordered = TRUE)))
responses <- 
  response %>%
  use_series(response)
```

## Introduction

<hr>

In this module, we will learn to: 

- tabulate levels
- reorder levels
- reverse levels
- collapse levels
- recode levels
- recategorize levels
- shift levels

## Case Study

<hr>

We will use a case study to explore the various features of the forcats package. You can download the data for the case study from [here](https://raw.githubusercontent.com/rsquaredacademy/datasets/master/web.csv) or directly import the data using the readr package. In this case study, we will:

- compute the frequency of different referrers
- collapse referrers with low sample size into a single group
- club traffic from social media websites into a new category
- group referrers with traffic below a threshold into a single category

## Data

<hr>

```{r show, exercise = TRUE, exercise.eval = FALSE, exercise.cap = 'Data'}
traffic <- read_csv('https://raw.githubusercontent.com/rsquaredacademy/datasets/master/web_traffic.csv',
  col_types = list(col_factor(levels = c("google", "facebook", "affiliates", 
    "bing", "yahoo", "twitter", "instagram", "unknown", "direct"))))

traffic
```

## Data

<hr>

```{r import2a, exercise = TRUE, exercise.eval = FALSE, exercise.cap = 'Data'}
traffics <- 
  traffic %>%
  use_series(traffics)

traffics
```
 
## Count 

<hr>

![](/images/fct_count.png){width=90%}


```{r cat2, exercise = TRUE, exercise.eval = FALSE, exercise.cap = 'Tabulate Referrers'}
fct_count(traffics)
```

## Levels

<hr>

```{r cat2b, exercise = TRUE, exercise.eval = FALSE, exercise.cap = 'Tabulate Referrers'}
levels(traffics)
```

## Reorder 

<hr>

![](/images/fct_infreq.png){width=90%}

## Reorder 

<hr>

```{r cat11, fig.align='center', fig.width=6, fig.height=4, exercise = TRUE, exercise.eval = FALSE, exercise.cap = 'Reorder Referrers'}
traffics %>%
  fct_infreq() %>%
  levels()
```

## Reorder 

<hr>

![](/images/fct_inorder.png){width=90%}

## Reorder

<hr>

```{r cat4, fig.align='center', fig.width=6, fig.height=4, exercise = TRUE, exercise.eval = FALSE, exercise.cap = 'Referrer Frequency'}
traffics %>%
  fct_inorder() %>%
  levels()
```

## Reverse Levels

<hr>

![](/images/fct_rev.png){width=90%}

## Reverse Levels

<hr>

```{r cat25, exercise = TRUE, exercise.eval = FALSE, exercise.cap = 'Data'}
traffics %>%
  fct_rev() %>%
  levels()
```

## Collapse Categories

<hr>

![](/images/fct_collapse.png){width=90%}

## Collapse Categories

<hr>

```{r cat7, exercise = TRUE, exercise.eval = FALSE, exercise.cap = 'Data'}
traffics %>% 
  fct_collapse(
  social = c("facebook", "twitter", "instagram"),
  search = c("google", "bing", "yahoo")) %>% 
  fct_count() 
```

## Lump Categories

<hr>

![](/images/fct_lump_1.png){width=90%}

## Lump Categories

<hr>

```{r cat8, exercise = TRUE, exercise.eval = FALSE, exercise.cap = 'Data'}
fct_count(traffics)
```

```{r cat8b, exercise = TRUE, exercise.eval = FALSE, exercise.cap = 'Data'}
traffics %>% 
  fct_lump() %>% 
  table()
```

## Lump Categories

<hr>

```{r cat9, exercise = TRUE, exercise.eval = FALSE, exercise.cap = 'Data'}
traffics %>% 
  fct_count() %>% 
  arrange(desc(n))
```

```{r cat17, exercise = TRUE, exercise.eval = FALSE, exercise.cap = 'Data'}
traffics %>% 
  fct_lump(n = 3) %>% 
  table()
```

## Lump Categories

<hr>

![](/images/fct_lump_2.png){width=90%}

## Lump Categories

<hr>

```{r cat12, exercise = TRUE, exercise.eval = FALSE, exercise.cap = 'Data'}
traffics %>% 
  fct_count() %>%
  mutate(
    percent = round((n / sum(n)) * 100, 2)
  )
```

```{r cat16, exercise = TRUE, exercise.eval = FALSE, exercise.cap = 'Data'}
traffics %>% 
  fct_lump(prop = 0.1) %>% 
  table()
```

## Lump Categories

<hr>

```{r cat13, exercise = TRUE, exercise.eval = FALSE, exercise.cap = 'Data'}
traffics %>% 
  fct_count() %>%
  mutate(
    percent = round((n / sum(n)) * 100, 2)
  )
```

```{r cat18, exercise = TRUE, exercise.eval = FALSE, exercise.cap = 'Data'}
traffics %>% 
  fct_lump(prop = 0.15) %>% 
  table()
```

## Lump Categories

<hr>

```{r cat14, exercise = TRUE, exercise.eval = FALSE, exercise.cap = 'Data'}
traffics %>% 
  fct_count() %>% 
  arrange(n)
```

```{r cat19, exercise = TRUE, exercise.eval = FALSE, exercise.cap = 'Data'}
traffics %>% 
  fct_lump(n = -3) %>% 
  table()
```

## Lump Categories

<hr>

```{r cat15, exercise = TRUE, exercise.eval = FALSE, exercise.cap = 'Data'}
traffics %>% 
  fct_count() %>%
  mutate(
    percent = round((n / sum(n)) * 100, 2)
  )
```

```{r cat20, exercise = TRUE, exercise.eval = FALSE, exercise.cap = 'Data'}
traffics %>% 
  fct_lump(prop = -0.1) %>% 
  table()
```

## Replace Levels

<hr>

![](/images/fct_others_1.png){width=90%}

## Replace Levels with Other

<hr>

```{r other_1, exercise = TRUE, exercise.eval = FALSE, exercise.cap = 'Data'}
fct_other(traffics, keep = c("google", "yahoo")) %>%
  levels()
```

## Replace Levels

<hr>

![](/images/fct_others_2.png){width=90%}

## Replace Levels with Other

<hr>

```{r other_2, exercise = TRUE, exercise.eval = FALSE, exercise.cap = 'Data'}
fct_other(traffics, drop = c("instagram", "twitter")) %>%
  levels()
```

## Recode Levels

<hr>

![](/images/fct_recode.png){width=90%}

## Recode Levels

<hr>

```{r recode, exercise = TRUE, exercise.eval = FALSE, exercise.cap = 'Data'}
fct_recode(traffics, search = "bing", search = "yahoo", search = "google",
  social = "facebook", social = "twitter", social = "instagram") %>%
  levels()
```

## Reorder Levels

<hr>

![](/images/fct_relevel_1.png){width=90%}

## Reorder Levels

<hr>

```{r relevel_1, exercise = TRUE, exercise.eval = FALSE, exercise.cap = 'Data'}
fct_relevel(traffics, "twitter") %>%
  levels()
```

## Reorder Levels

<hr>


![](/images/fct_relevel_2.png){width=90%}

## Reorder Levels

<hr>

```{r relevel_2, exercise = TRUE, exercise.eval = FALSE, exercise.cap = 'Data'}
fct_relevel(traffics, "google", after = 2) %>%
  levels()
```

## Reorder Levels

<hr>

![](/images/fct_relevel_3.png){width=90%}

## Reorder Levels

<hr>

```{r relevel_3, exercise = TRUE, exercise.eval = FALSE, exercise.cap = 'Data'}
fct_relevel(traffics, "facebook", after = Inf) %>%
  levels()
```

## Data 

<hr>

```{r import3, exercise = TRUE, exercise.eval = FALSE, exercise.cap = 'Data'}
response <- read_csv('https://raw.githubusercontent.com/rsquaredacademy/datasets/master/response.csv',
  col_types = list(col_factor(levels = c("like", "like somewhat", "neutral", 
    "dislike somewhat", "dislike"), ordered = TRUE)))

response
```

## Data

<hr>

```{r import2b, exercise = TRUE, exercise.eval = FALSE, exercise.cap = 'Data'}
responses <- 
  response %>%
  use_series(response)

responses
```

## Shift Levels

<hr>

![](/images/fct_shift_1.png){width=90%}

## Shift Levels

<hr>

```{r shift_1, exercise = TRUE, exercise.eval = FALSE, exercise.cap = 'Data'}
fct_shift(responses, 2) %>%
  levels()
```

## Shift Levels

<hr>

![](/images/fct_shift_2.png){width=90%}

## Shift Levels

<hr>

```{r shift_2, exercise = TRUE, exercise.eval = FALSE, exercise.cap = 'Data'}
fct_shift(responses, -2) %>%
  levels()
```


